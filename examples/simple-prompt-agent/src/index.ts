/**
 * Welcome to Cloudflare Workers! This is your first worker.
 *
 * - Run `npm run dev` in your terminal to start a development server
 * - Open a browser tab at http://localhost:8787/ to see your worker in action
 * - Run `npm run deploy` to publish your worker
 *
 * Learn more at https://developers.cloudflare.com/workers/
 */

import { Hono } from 'hono';
import { 
	AgentEnv,
	applyPermissionlessAgentSessionRouter,
} from '@xava-labs/agent';
// Import the ToolsService directly 
import { ToolboxService } from '@xava-labs/agent/services';
import { CoreMessage, LanguageModel } from 'ai';
import { createAnthropic } from '@ai-sdk/anthropic';
import { createOpenAI } from '@ai-sdk/openai';
import { AiSdkAgent } from '@xava-labs/agent/aisdk';
// Define AI provider type
type AIProvider = 'anthropic' | 'openai';

// Define a type that extends both the autogenerated Env and AgentEnv
type EnvWithAgent = Env & AgentEnv;

// Function to validate if a value is a valid AIProvider
function isValidAIProvider(value: unknown): value is AIProvider {
	return value === 'anthropic' || value === 'openai';
}

// Use type assertion to make Hono app compatible with AgentRouterBuilder
const app = new Hono<{ Bindings: EnvWithAgent }>();
applyPermissionlessAgentSessionRouter(app);

export class SimplePromptAgent extends AiSdkAgent<EnvWithAgent> {
	constructor(state: DurableObjectState, env: EnvWithAgent) {
		// Validate AI_PROVIDER before using it
		if (!isValidAIProvider(env.AI_PROVIDER)) {
			throw new Error(`Invalid AI provider: ${env.AI_PROVIDER}. Expected 'anthropic' or 'openai'.`);
		}
		
		let model : LanguageModel;
		// This is just an example, ideally you only want ot inlcude models that you plan to use for your agent itself versus multiple models
		switch (env.AI_PROVIDER) {
			case 'anthropic':
				const anthropic = createAnthropic({
					apiKey: env.ANTHROPIC_API_KEY,
				});
				model = anthropic('claude-3-haiku-20240307');
				break;
			case 'openai':
				const openai = createOpenAI({
					apiKey: env.OPEN_AI_API_KEY,
				});
				model = openai('gpt-3.5-turbo');
				break;
			default:
				// This should never happen due to validation above, but TypeScript requires this
				throw new Error(`Unsupported AI provider: ${env.AI_PROVIDER}`);
		}

		super(state, env, model, [new ToolboxService(env)]);
	}

	async processMessage(sessionId: string, messages: CoreMessage[]): Promise<Response> {
		console.log('Processing message', messages);

		const result = await this.streamText(sessionId, {
			model: this.model,
			prompt: 'You are a helpful assistant that can answer questions and help with managing a TODO list',
		});

		return result.toDataStreamResponse();
	}
}

// Export the worker handler
export default {
	async fetch(request: Request, env: EnvWithAgent, ctx: ExecutionContext): Promise<Response> {
		// Bootstrap the agent worker with the namespace
		return app.fetch(request, env, ctx);
	}
};
