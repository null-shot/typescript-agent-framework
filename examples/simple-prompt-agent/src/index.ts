/**
 * Welcome to Cloudflare Workers! This is your first worker.
 *
 * - Run `npm run dev` in your terminal to start a development server
 * - Open a browser tab at http://localhost:8787/ to see your worker in action
 * - Run `npm run deploy` to publish your worker
 *
 * Learn more at https://developers.cloudflare.com/workers/
 */

import { Hono } from 'hono';
import { 
	Agent,
	AgentEnv,
	applyPermissionlessAgentSessionRouter,
} from '@xava-labs/agent';
// Import the ToolsService directly 
import { ToolboxService } from '@xava-labs/agent/services';
import { CoreMessage, LanguageModel } from 'ai';
import { createAnthropic } from '@ai-sdk/anthropic';
import { createOpenAI } from '@ai-sdk/openai';

// Define AI provider type
type AIProvider = 'anthropic' | 'openai';

// Define a type that extends both the autogenerated Env and AgentEnv
type EnvWithAgent = Env & AgentEnv;

// Function to validate if a value is a valid AIProvider
function isValidAIProvider(value: unknown): value is AIProvider {
	return value === 'anthropic' || value === 'openai';
}

// Use type assertion to make Hono app compatible with AgentRouterBuilder
const app = new Hono<{ Bindings: EnvWithAgent }>();
applyPermissionlessAgentSessionRouter(app);

export class SimplePromptAgent extends Agent<EnvWithAgent> {
	private ToolboxService: ToolboxService;
	constructor(state: DurableObjectState, env: EnvWithAgent) {
		// Validate AI_PROVIDER before using it
		if (!isValidAIProvider(env.AI_PROVIDER)) {
			throw new Error(`Invalid AI provider: ${env.AI_PROVIDER}. Expected 'anthropic' or 'openai'.`);
		}
		
		let model : LanguageModel;
		// This is just an example, ideally you only want ot inlcude models that you plan to use for your agent itself versus multiple models
		switch (env.AI_PROVIDER) {
			case 'anthropic':
				const anthropic = createAnthropic({
					apiKey: env.ANTHROPIC_API_KEY,
				});
				model = anthropic('claude-3-haiku-20240307');
				break;
			case 'openai':
				const openai = createOpenAI({
					apiKey: env.OPEN_AI_API_KEY,
				});
				model = openai('gpt-3.5-turbo');
				break;
			default:
				// This should never happen due to validation above, but TypeScript requires this
				throw new Error(`Unsupported AI provider: ${env.AI_PROVIDER}`);
		}

		const toolboxService = new ToolboxService(env);

		super(state, env, model, [toolboxService])
		this.ToolboxService = toolboxService;
	}

	async processMessage(messages: CoreMessage[], sessionId: string): Promise<Response> {
		console.log('Processing message', messages);

		console.log('Tools', this.ToolboxService.getTools());
		const result = await this.streamText(sessionId, {
			model: this.model,
			system: 'You are a helpful assistant.',
			messages,
			onError: (error) => {
				console.error('Error processing message:', error);
			},
			tools: this.ToolboxService.getTools(),
			maxSteps: 10,
		});

		return result.toDataStreamResponse();
	}
}

// Export the worker handler
export default {
	async fetch(request: Request, env: Env, ctx: ExecutionContext): Promise<Response> {
		// Bootstrap the agent worker with the namespace
		return app.fetch(request, env as EnvWithAgent, ctx);
	}
};
